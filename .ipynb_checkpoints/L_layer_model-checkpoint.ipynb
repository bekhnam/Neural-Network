{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44bbac0",
   "metadata": {},
   "source": [
    "# Deep Neural Network for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a9e473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba0388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed51bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    A = np.maximum(0, Z)\n",
    "    assert(A.shape == Z.shape)\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26bd8084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    assert(dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6293fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    assert(dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "370469c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1])\n",
    "        parameters[\"b\" + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        assert(parameters[\"W\" + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters[\"b\" + str(l)].shape == (layer_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e546ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d04bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    Z = W.dot(A) + b\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ec1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    if activation == 'sigmoid':\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == 'relu':\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    assert(A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "442b9774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters)\n",
    "    \n",
    "    # implement [Linear->ReLU]*(L-1)\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)], activation=\"relu\")\n",
    "        caches.append(cache)\n",
    "    # implement Linear->Sigmoid\n",
    "    AL, cache = linear_activation_forward(A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)], activation=\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    assert(AL.shape == (1, X.shape[1]))\n",
    "    \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c875fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    cost = (1./m) * (-np.dot(Y, np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6374b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = (1./m) * np.dot(dZ, A_prev.T)\n",
    "    db = (1./m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    assert(dW.shape == W.shape)\n",
    "    assert(db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76a586f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == 'sigmoid':\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4c1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (there are (L-1) or them, indexes from 0 to L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (there is one, index L-1)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    # initializing the backpropagation\n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1-Y, 1-AL))\n",
    "    # Lth layer (Sigmoid->Linear) gradients\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation='sigmoid')\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (ReLU->Linear) gradients\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, activation='relu')\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l+1)] = dW_temp\n",
    "        grads[\"db\" + str(l+1)] = db_temp\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b77fb95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    L = len(parameters)\n",
    "    # update rule for each parameter\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4921e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters)\n",
    "    p = np.zeros((1, m))\n",
    "    # forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0, i] > 0.5:\n",
    "            p[0, i] = 1\n",
    "        else:\n",
    "            p[0, i] = 0\n",
    "    \n",
    "    print(\"Accuracy: \" + str(np.sum((p == y)/m)))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbc52fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mislabeled_images(classes, X, y, p):\n",
    "    \"\"\"\n",
    "    Plots images where predictions and truth were different\n",
    "    X -- dataset\n",
    "    y -- true labels\n",
    "    p -- predictions\n",
    "    \"\"\"\n",
    "    a = p + y\n",
    "    mislabeled_indices = np.asarray(np.where(a == 1))\n",
    "    plt.rcParams[\"figure.figsize\"] = (40.0, 40.0)\n",
    "    num_images = len(mislabeled_indices[0])\n",
    "    for i in range(num_images):\n",
    "        index = mislabeled_indices[1][i]\n",
    "        plt.subplot(2, num_images, i+1)\n",
    "        plt.imshow(X[:, index].reshape(64, 64, 3), interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Prediction: \" + classes[int(p[0, index])].decode('utf-8') + \" \\n Class: \" + classes[y[0, index]].decode(\"utf-8\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f3217c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b9b635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n",
    "# reshape the training and test examples\n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "# standardize data to have feature values between 0 and 1\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3794f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants defining the model\n",
    "layers_dims = [12288, 20, 7, 5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea579df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn_app_utils_v3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c003546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations=3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    # parameters initialization\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    # loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "        # forward propagation: [Linear->ReLU]*(L-1)->Linear->Sigmoid\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        # compute cost\n",
    "        cost = compute_cost(AL, Y)\n",
    "        # backward propagation\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        # update parameters\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if print_cost and i % 100 == 0 or i == num_iterations -1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "        \n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62209ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.7717493284237686\n",
      "Cost after iteration 100: 0.6720534400822914\n",
      "Cost after iteration 200: 0.6482632048575212\n",
      "Cost after iteration 300: 0.6115068816101354\n",
      "Cost after iteration 400: 0.5670473268366111\n",
      "Cost after iteration 500: 0.54013766345478\n",
      "Cost after iteration 600: 0.5279299569455268\n",
      "Cost after iteration 700: 0.46547737717668514\n",
      "Cost after iteration 800: 0.3691258524959279\n",
      "Cost after iteration 900: 0.39174697434805356\n",
      "Cost after iteration 1000: 0.3151869888600615\n",
      "Cost after iteration 1100: 0.27269984417893844\n",
      "Cost after iteration 1200: 0.23741853400268137\n",
      "Cost after iteration 1300: 0.19960120532208644\n",
      "Cost after iteration 1400: 0.18926300388463305\n",
      "Cost after iteration 1500: 0.1611885466582775\n",
      "Cost after iteration 1600: 0.14821389662363316\n",
      "Cost after iteration 1700: 0.13777487812972944\n",
      "Cost after iteration 1800: 0.1297401754919012\n",
      "Cost after iteration 1900: 0.12122535068005211\n",
      "Cost after iteration 2000: 0.11382060668633712\n",
      "Cost after iteration 2100: 0.10783928526254133\n",
      "Cost after iteration 2200: 0.10285466069352679\n",
      "Cost after iteration 2300: 0.10089745445261787\n",
      "Cost after iteration 2400: 0.09287821526472397\n",
      "Cost after iteration 2499: 0.088439943441702\n"
     ]
    }
   ],
   "source": [
    "parameters, costs = L_layer_model(train_x, train_y, layers_dims, num_iterations=2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04fc183d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9856459330143539\n"
     ]
    }
   ],
   "source": [
    "pred_train = predict(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6e73f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f9356df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "y= 1.0, your L-layer model predicts a \"cat\" picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# test some images\n",
    "num_px = train_x_orig.shape[1]\n",
    "test_image = \"images/non_cat.jpg\"\n",
    "my_label_y = [0]\n",
    "image = np.array(Image.open(test_image).resize((num_px, num_px)))\n",
    "plt.imshow(image)\n",
    "image = image / 255.\n",
    "image = image.reshape((1, num_px * num_px * 3)).T\n",
    "my_predicted_image = predict(image, my_label_y, parameters)\n",
    "print(\"y= \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") + \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9c0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
